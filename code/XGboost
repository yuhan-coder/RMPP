import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import StandardScaler
from imblearn.under_sampling import RandomUnderSampler
from xgboost import XGBClassifier
import matplotlib.pyplot as plt

# Load the data
data = pd.read_csv("RMMP.csv")

# Prepare features and target
X = data.iloc[:, :-1]  # All columns except the target
y = data.iloc[:, 29]   # Assuming target is in the 30th column

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Apply Random Under-Sampling
X_train, y_train = RandomUnderSampler(random_state=2).fit_resample(X_train, y_train)

# Initialize XGBoost model
xgb_model = XGBClassifier()

# Fit the model
xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict(X_test)

# Predict probabilities
y_score = xgb_model.predict_proba(X_test)[:, 1]

# Calculate AUC
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)
print(f"AUC: {roc_auc:.3f}")

# Calculate other metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Print the metrics
print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

# Cross-validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Perform cross-validation and store results
cv_results = {score: cross_val_score(xgb_model, X_test, y_test, cv=kf, scoring=score, n_jobs=-1) for score in scoring}

# Print cross-validation results
for score, result in cv_results.items():
    print(f"{score.capitalize()}: {result.mean():.3f}")

# Additional metrics using cross-validation predictions
y_score_cv = cross_val_predict(xgb_model, X_train, y_train, cv=kf, method='predict_proba', n_jobs=-1)
fpr_cv, tpr_cv, _ = roc_curve(y_train, y_score_cv[:, 1])
roc_auc_cv = auc(fpr_cv, tpr_cv)

# Print cross-validated AUC
print(f"Cross-validated ROC AUC: {roc_auc_cv:.3f}")
